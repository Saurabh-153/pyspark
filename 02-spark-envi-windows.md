

# Spark Environment Setup on Windows

- download spark latest version
https://www.apache.org/dyn/closer.lua/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz

- set the SPARK_HOME environment variable to the spark path


- download winutils.exe
https://github.com/steveloughran/winutils
- set the HARDOOP_HOME environment variable to the winutils.exe path

- set PYSPARK_PYTHON environment variable to the python path

---


start the pyspark shell
```bash
pyspark
```





